# Implementing Splunk Data Stream Processor (DSP)

**Product ID**: 25934
**Category ID**: nan
**Modality**: 2
**Active**: True
**Language**: en
**Product Code**: ISDSP
**Vendor Code**: SP
**Vendor Name**: Splunk
**URL**: [Course Link](https://www.fastlaneus.com/course/splunk-isdsp)

## Objective
- Introduction to Splunk Data Stream Processor
- Deploying a DSP cluster
- Prepping Sources and Sinks
- Building Pipelines - Basics
- Building Pipelines - Deep Dive
- Working with 3rd party Data Feeds
- Working with Metric Data
- Monitoring DSP Environment

## Essentials
Required:


- Splunk Enterprise System Administration (SESA)
- Splunk Enterprise Data Administration (SEDA)
Recommended:


- Architecting Splunk Enterprise Deployments (ASED)
- Working knowledge of:
- Distributed system architectures
- Apache Kafka (user level)
- Apache Flink (user level)
- Kubernetes (admin level)

## Audience
This 4-day module is designed for the experienced Splunk administrators who are new to Splunk DSP.

## Outline
Topic 1 – Introduction to DSP


- Review Splunk deployment options and challenges
- Describe the purpose and value of Splunk DSP
- Understand DSP concepts and terminologies
Topic 2 – Deploying a DSP Cluster


- List DSP core components and system requirements
- List DSP core components and system requirements
- Describe installation options and steps
- Check DSP service status
- Learn to navigate in DSP UI
- Use scloud
Topic 3 – Prepping Sources and Sinks


- Ingest data with DSP REST API service
- Configure DSP source connections for Splunk data
- Configure DSP sink connections for Splunk indexers
- Create Splunk-to Splunk pass-through pipelines
Topic 4 – Building Pipelines - Basics


- Describe the basic elements of a DSP pipeline
- Create data pipelines with the DSP canvas and SPL2
- List DSP pipeline commands
- Use scalar functions to convert data types and schema
- Filter and route data to multiple sinks

 
Topic 5 – Building Pipelines - Deep Dive


- Manipulate pipeline options:
- Extract
- Transform
- Obfuscate
- Aggregate and conditional trigger

 
Topic 6 – Working with 3rd party Data Feeds


- Read from and write data to pub-sub systems like Kafka
- List sources supported with the collect service
- Transform data from Kafka and normalize
- Write to S3

 
Topic 7 – Working with Metric Data


- Onboard metric data into DSP
- Transform metric data for Splunk indexers and SignalFx
- Send metric data to Splunk indexers
- Send metric data to Splunk SignalFx

 
Topic 8 – Monitoring DSP Environment


- Back up DSP pipelines
- Monitor DSP environment
- Describe steps to isolate DSP service issues
- Scale DSP
- Replace DSP master node
- Upgrade DSP cluster

## Summary
nan

## Course Duration
18 hours

## Last Changed
2024-08-26T22:46:03.000Z
